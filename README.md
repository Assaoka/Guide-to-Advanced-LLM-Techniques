<h1 align="center"> ü§ñ Guia Pr√°tico de T√©cnicas Avan√ßadas com LLMs para Classifica√ß√£o de Texto ü§ñ <br>
  <img src="https://img.shields.io/badge/UNIFESP-Universidade%20Federal%20de%20S%C3%A3o%20Paulo-215a36" alt="UNIFESP">
  <img src="https://img.shields.io/badge/Jo%C3%A3o%20Assaoka,%20Lilian%20Berton-2025.1-215a36" alt="Jo√£o Victor Assaoka">
</h1>

&emsp;&emsp; Este reposit√≥rio √© um tutorial completo e pr√°tico que explora metodologias avan√ßadas para a classifica√ß√£o de sentimentos e emo√ß√µes em textos, utilizando Modelos de Linguagem de Grande Porte (LLMs). O projeto foi desenvolvido para ser acess√≠vel, com todos os exemplos execut√°veis em ambientes gratuitos como o Google Colab.

# üéØ Objetivo
&emsp;&emsp; O objetivo deste guia √© desmistificar e centralizar o conhecimento sobre t√©cnicas de LLMs, oferecendo um caminho claro e progressivo para estudantes, pesquisadores e desenvolvedores. Atrav√©s de uma tarefa pr√°tica de an√°lise de sentimentos em not√≠cias financeiras brasileiras, demonstramos e comparamos abordagens como:
- Engenharia de Prompt: Zero-Shot, Few-Shot e Chain-of-Thought (CoT).
- Ensembles de LLMs: Vota√ß√£o Majorit√°ria e Negocia√ß√£o entre modelos.
- Fine-Tuning Eficiente: Ajuste fino com QLoRA (Quantized Low-Rank Adaptation).
- Destila√ß√£o de Conhecimento: Treinamento de um modelo menor a partir de um modelo "professor" maior.

# üöÄ Como Come√ßar
Todos os notebooks foram projetados para serem executados de forma independente no Google Colab. N√£o √© necess√°rio configurar um ambiente local. Basta clicar nos links abaixo para abrir e executar cada m√≥dulo diretamente no seu navegador.

# üìö M√≥dulos do Tutorial
O guia √© dividido em quatro m√≥dulos progressivos.

#### [M√≥dulo 1: A Base - LangChain e Sa√≠das Estruturadas](M√≥dulo_1_LangChain_e_Sa√≠das_Estruturadas.ipynb)
Neste m√≥dulo, constru√≠mos a funda√ß√£o para interagir com LLMs de forma program√°tica. Abordamos a configura√ß√£o de APIs (Groq e Sabi√°), a orquestra√ß√£o com LangChain e a import√¢ncia de gerar sa√≠das estruturadas (JSON) para integrar os modelos em aplica√ß√µes reais.

#### [M√≥dulo 2: A Arte e a Ci√™ncia da Engenharia de Prompt](M√≥dulo_2_Arte_e_Ci√™ncia_da_Engenharia_de_Prompt.ipynb)
Aqui, aprofundamos as estrat√©gias para guiar o comportamento dos LLMs. Comparamos as abordagens Zero-Shot, Few-Shot e a poderosa t√©cnica de Chain-of-Thought (CoT), que incentiva o modelo a "pensar passo a passo" para melhorar a precis√£o em tarefas complexas.

#### [M√≥dulo 3: Ensembles de LLMs - A Sabedoria das Multid√µes](M√≥dulo_3_Ensembles_de_LLMs_A_Sabedoria_das_Multid√µes.ipynb)
Este m√≥dulo explora como combinar as predi√ß√µes de m√∫ltiplos modelos para obter resultados mais robustos. Implementamos duas estrat√©gias de ensemble: a Vota√ß√£o Majorit√°ria (incluindo a t√©cnica de Self-Consistency) e a Negocia√ß√£o, que simula um debate estruturado entre modelos para alcan√ßar um consenso.

#### [M√≥dulo 4: Fine-Tuning Eficiente - Especializando seu Pr√≥prio LLM](M√≥dulo_4_Fine_Tuning_Eficiente_Especializando_seu_Proprio_LLM.ipynb)
No m√≥dulo final, adaptamos o pr√≥prio modelo √† nossa tarefa espec√≠fica. Demonstramos como realizar o fine-tuning de um LLM de forma eficiente em uma GPU gratuita, utilizando a t√©cnica QLoRA. Al√©m disso, introduzimos a destila√ß√£o de conhecimento como uma forma de criar modelos menores e mais r√°pidos, treinados para imitar o comportamento de um "professor" maior.

# üí° [Guia de Decis√£o](Guia_de_Decis√£o.md)
&emsp;&emsp; Para ajudar na escolha da metodologia mais adequada para o seu projeto, o artigo associado a este guia oferece um guia de decis√£o pr√°tico, com base em prioridades como precis√£o, interpretabilidade e lat√™ncia.

Sinta-se √† vontade para explorar, executar e adaptar os notebooks para seus pr√≥prios projetos!