{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgxUrIBXtZQHD3+fC7K+AJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Assaoka/Guide-to-Advanced-LLM-Techniques/blob/main/M%C3%B3dulo_3_Ensembles_de_LLMs_A_Sabedoria_das_Multid%C3%B5es.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Módulo 3: Ensembles de LLMs - A Sabedoria das Multidões"
      ],
      "metadata": {
        "id": "wg-qHhguTI8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução"
      ],
      "metadata": {
        "id": "nCz1fxpITKUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos módulos anteriores, focamos em como aprimorar a interação com um único modelo através da engenharia de prompt. Agora, vamos explorar uma técnica poderosa emprestada do aprendizado de máquina tradicional: os ensembles.\n",
        "\n",
        "A ideia central de um ensemble é que \"várias cabeças pensam melhor que uma\". Em vez de confiar na resposta de um único modelo, combinamos as predições de múltiplos modelos (ou múltiplas predições do mesmo modelo) para chegar a uma decisão final mais robusta e precisa. LLMs, apesar de seu poder, podem ser suscetíveis a vieses ou alucinações. Usar um ensemble pode mitigar esses riscos e aumentar a confiabilidade geral do sistema."
      ],
      "metadata": {
        "id": "X8eAMCj1TNBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Votação Majoritária"
      ],
      "metadata": {
        "id": "uiqIvXByTQ1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A votação é a forma mais intuitiva de ensemble. A ideia é consultar vários \"especialistas\" independentes e adotar a resposta da maioria. No contexto de LLMs, esses especialistas podem ser:\n",
        "1. Diferentes Modelos: Você pode fazer a mesma pergunta para o Llama 3, Mixtral e Sabiá, e depois contar os votos de cada um.\n",
        "2. Diferentes Prompts: Usar vários prompts (ex: um Zero-Shot, um Few-Shot) com o mesmo modelo.\n",
        "3. Múltiplas Execuções do Mesmo Modelo: Esta é a abordagem conhecida como Self-Consistency (Autoconsistência), proposta por Wang et al. (2022) [1]. Executamos o mesmo prompt várias vezes com uma temperatura > 0 para gerar respostas diversas e escolhemos a mais frequente.\n",
        "\n",
        "Vamos implementar a abordagem de Self-Consistency, pois é a mais prática quando se tem acesso a uma única API."
      ],
      "metadata": {
        "id": "Dw-_YBJaTVDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-core langchain-community langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPiVCK-qTkGr",
        "outputId": "dd7b8385-59fa-43b0-b5fe-7407b40d22db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_groq = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "uChGcceXTsJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "class ClassificacaoNoticia(BaseModel):\n",
        "    emocao: Literal[\"Felicidade\", \"Tristeza\", \"Nojo\", \"Raiva\",\n",
        "                    \"Medo\", \"Surpreza\", \"Desprezo\"] = Field(\n",
        "                    description=\"A emoção primária transmitida pelo texto. Estamos usando como padrão as emoções universais de ekman\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=ClassificacaoNoticia)\n",
        "formato = parser.get_format_instructions()\n"
      ],
      "metadata": {
        "id": "OFNQQIZOTyKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Classifique a notícia abaixo quanto a emoção.\n",
        "{format_instructions}\n",
        "Notícia: {noticia}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    template=template,\n",
        "    partial_variables={\"format_instructions\": formato}\n",
        ")"
      ],
      "metadata": {
        "id": "aFjuHftWUmnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm_groq | parser\n",
        "chain.invoke(\"Nesse cenário de instabilidade, os investidores não sabem o que fazer.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX7wfKtEU_SL",
        "outputId": "940303ea-cf82-43eb-af5a-70199b3a3482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificacaoNoticia(emocao='Medo')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def votacao(chain, texto: str, n: int) -> ClassificacaoNoticia:\n",
        "    votos = [chain.invoke(texto) for _ in range(n)]\n",
        "    vals = [voto.emocao for voto in votos]\n",
        "    conts = {}\n",
        "    for val in vals:\n",
        "        print(val)\n",
        "        if val in conts:\n",
        "            conts[val] += 1\n",
        "        else:\n",
        "            conts[val] = 1\n",
        "\n",
        "    return ClassificacaoNoticia(emocao=max(conts, key=conts.get))\n",
        "\n",
        "\n",
        "votacao(chain, \"Os resultados fiscais do primeiro semestre de 2024 indicam que, no curto prazo, a meta fiscal de -0,25% do PIB é mais viável, apesar das incertezas de médio e longo prazo devido aos desafios fiscais e ao aumento das despesas obrigatórias. O desempenho das receitas líquidas foi positivo, impulsionado pelas medidas legislativas de arrecadação, mas o crescimento das despesas, especialmente com benefícios previdenciários, elevou o déficit primário para R$ 68,7 bilhões, agravando o cenário fiscal. Apesar das medidas de contenção adotadas, a sustentabilidade das contas públicas a longo prazo permanece ameaçada, exigindo soluções concretas e uma postura cautelosa para os próximos anos.\", 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVA9DfWvUfOt",
        "outputId": "fd7a8af1-ae5b-41ad-ff1e-f8a79cbe3ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tristeza\n",
            "Tristeza\n",
            "Tristeza\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificacaoNoticia(emocao='Tristeza')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Negociação"
      ],
      "metadata": {
        "id": "pAWUfO0TWrYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E se, em vez de votar de forma independente, os \"especialistas\" pudessem debater e refinar suas ideias? Essa é a premissa da Negociação, uma técnica que simula um processo de argumentação para resolver discordâncias. O trabalho de Sun et al. (2023) [2] explora essa ideia, mostrando que um debate estruturado pode ajudar a resolver ambiguidades.\n",
        "\n",
        "Vamos implementar um framework de debate iterativo com dois papéis:\n",
        "1. Gerador: Gera a análise e classificação inicial.\n",
        "2. Discriminador: Revisa a análise do propositor, busca falhas, pontos de vista alternativos ou ambiguidades e oferece uma contra-análise.\n",
        "\n",
        "O processo é um loop:\n",
        "1. O Gerador faz uma análise inicial.\n",
        "2. O Discriminador avalia a análise. Podendo concordar ou apresentar uma contra proposta.\n",
        "3. O Propositor revisa sua análise com base na crítica. E pode concordar ou enviar uma contra proposta.\n",
        "4. O ciclo se repete até um número máximo de rodadas ou até que um consenso seja alcançado."
      ],
      "metadata": {
        "id": "I-9IIHbhWwAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gerador = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "discriminador = ChatGroq(\n",
        "    model=\"qwen-qwq-32b\",\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "3aIjooGSXfJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Negociacao(BaseModel):\n",
        "    raciocinio: str = Field(description=\"Linha de raciocínio passo a passo do modelo até chegar em uma decisão.\")\n",
        "    concordo: bool = Field(description=\"Representa se o modelo concorda ou não com o modelo anterior. Inicia como False.\")\n",
        "    emocao: Literal[\"Felicidade\", \"Tristeza\", \"Nojo\", \"Raiva\",\n",
        "                    \"Medo\", \"Surpreza\", \"Desprezo\"] = Field(\n",
        "                    description=\"A emoção primária transmitida pelo texto. Estamos usando como padrão as emoções universais de ekman\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Negociacao)\n",
        "formato = parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "JwCg4cKgX_uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador1_template = \"\"\"Classifique a notícia abaixo quanto a emoção.\n",
        "{format_instructions}\n",
        "Notícia: {noticia}\n",
        "\"\"\"\n",
        "\n",
        "gerador1_prompt = PromptTemplate.from_template(\n",
        "    template=gerador1_template,\n",
        "    partial_variables={\"format_instructions\": formato}\n",
        ")"
      ],
      "metadata": {
        "id": "BU3IYrTSX7NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminador1_template = \"\"\"Você está em um debate com outro agente. A tarefa de vocês é classificar a notícia abaixo quanto a emoção.\n",
        "{format_instructions}\n",
        "Notícia: {noticia}\n",
        "Gerador: {gerador}\n",
        "\"\"\"\n",
        "\n",
        "discriminador1_prompt = PromptTemplate.from_template(\n",
        "    template=discriminador1_template,\n",
        "    partial_variables={\"format_instructions\": formato}\n",
        ")"
      ],
      "metadata": {
        "id": "TID39dN4YzFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterações_template = \"\"\"Você está em um debate com outro agente. A tarefa de vocês é classificar a notícia abaixo quanto a emoção.\n",
        "{format_instructions}\n",
        "Notícia: {noticia}\n",
        "sua proposta: {analise}\n",
        "Contra proposta: {contra_proposta}\n",
        "\"\"\"\n",
        "\n",
        "iterações_prompt = PromptTemplate.from_template(\n",
        "    template=iterações_template,\n",
        "    partial_variables={\"format_instructions\": formato}\n",
        ")"
      ],
      "metadata": {
        "id": "YgyY6_weZAQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inicio = gerador1_prompt | gerador | parser\n",
        "discriminar = discriminador1_prompt | discriminador | parser\n",
        "iterações1 = iterações_prompt | gerador | parser\n",
        "iterações2 = iterações_prompt | discriminador | parser"
      ],
      "metadata": {
        "id": "pafHW1-LZjAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def negociacao(noticia: str, n: int = 3):\n",
        "    historico = [inicio.invoke({\"noticia\": noticia})]\n",
        "    historico.append(discriminar.invoke({\"noticia\": noticia, \"gerador\": historico[-1].raciocinio}))\n",
        "    for i in range(n-2):\n",
        "        if i % 2 == 0:\n",
        "            historico.append(iterações1.invoke({\"noticia\": noticia,\n",
        "                                                \"analise\": historico[-2].raciocinio,\n",
        "                                                \"contra_proposta\": historico[-1].raciocinio}))\n",
        "        else:\n",
        "            historico.append(iterações2.invoke({\"noticia\": noticia,\n",
        "                                                \"analise\": historico[-2].raciocinio,\n",
        "                                                \"contra_proposta\": historico[-1].raciocinio}))\n",
        "        if historico[-1].concordo:\n",
        "            break\n",
        "    return historico\n"
      ],
      "metadata": {
        "id": "XGTkIrx1ZUlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negociacao(\"Os resultados fiscais do primeiro semestre de 2024 indicam que, no curto prazo, a meta fiscal de -0,25% do PIB é mais viável, apesar das incertezas de médio e longo prazo devido aos desafios\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxXstJYwaNw7",
        "outputId": "69b302ec-ba41-4dae-bf5c-16075f14f8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "Invalid json output: <think>\nOkay, I need to classify the given news article's emotion based on Ekman's basic emotions. The news is about the fiscal results for the first half of 2024 indicating that the short-term fiscal target of -0.25% of GDP is more viable, despite medium and long-term uncertainties due to challenges.\n\nFirst, I'll analyze the content. The key points are the viability of the short-term target and the mention of uncertainties. The fiscal target being achievable in the short term might suggest a positive outlook, which could relate to happiness. However, the presence of \"incertezas\" (uncertainties) and \"desafios\" (challenges) in the medium to long term introduces a negative aspect. \n\nNow, considering Ekman's emotions: happiness is positive, but the uncertainties might evoke another emotion. The uncertainty and challenges could lead to worry or fear. Since the main focus is on the viability now but uncertainty ahead, fear (Medo) might be the primary emotion here because it's about potential future problems. The article isn't purely positive because it highlights ongoing challenges, so happiness might be too strong. Surpresa isn't there, and no elements of disgust, sadness, or contempt. The mention of viability counterbalances some negativity, but the lingering uncertainties point more towards fear of future issues. \n\nThe previous model's answer (if any) isn't provided, but I need to state whether I agree. Since I'm the first, \"concordo\" starts as False by default. The reasoning should explain the balance between the positive short-term and negative long-term factors leading to Medo.\n</think>\n\n{\n  \"raciocinio\": \"A notícia menciona que a meta fiscal de -0,25% do PIB é viável no curto prazo, o que poderia sugerir uma perspectiva positiva. No entanto, a menção às 'incertezas de médio e longo prazo devido aos desafios' indica cautela e preocupação com o futuro. A combinação de uma realidade atual aparentemente controlada com ameaças potenciais no futuro tende a gerar **Medo**, uma vez que o foco está nas dificuldades que ainda estão por vir e não totalmente resolvidas.\",\n  \"concordo\": false,\n  \"emocao\": \"Medo\"\n}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/json.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Parse the JSON string into a Python dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# for the original string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-709802880.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnegociacao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Os resultados fiscais do primeiro semestre de 2024 indicam que, no curto prazo, a meta fiscal de -0,25% do PIB é mais viável, apesar das incertezas de médio e longo prazo devido aos desafios\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-24-3471742265.py\u001b[0m in \u001b[0;36mnegociacao\u001b[0;34m(noticia, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnegociacao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoticia\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhistorico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minicio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"noticia\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoticia\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhistorico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"noticia\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoticia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gerador\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhistorico\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraciocinio\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     ) -> T:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    198\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m                 output = cast(\n\u001b[1;32m   1939\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1941\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 197\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    198\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/pydantic.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/json.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid json output: {text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Invalid json output: <think>\nOkay, I need to classify the given news article's emotion based on Ekman's basic emotions. The news is about the fiscal results for the first half of 2024 indicating that the short-term fiscal target of -0.25% of GDP is more viable, despite medium and long-term uncertainties due to challenges.\n\nFirst, I'll analyze the content. The key points are the viability of the short-term target and the mention of uncertainties. The fiscal target being achievable in the short term might suggest a positive outlook, which could relate to happiness. However, the presence of \"incertezas\" (uncertainties) and \"desafios\" (challenges) in the medium to long term introduces a negative aspect. \n\nNow, considering Ekman's emotions: happiness is positive, but the uncertainties might evoke another emotion. The uncertainty and challenges could lead to worry or fear. Since the main focus is on the viability now but uncertainty ahead, fear (Medo) might be the primary emotion here because it's about potential future problems. The article isn't purely positive because it highlights ongoing challenges, so happiness might be too strong. Surpresa isn't there, and no elements of disgust, sadness, or contempt. The mention of viability counterbalances some negativity, but the lingering uncertainties point more towards fear of future issues. \n\nThe previous model's answer (if any) isn't provided, but I need to state whether I agree. Since I'm the first, \"concordo\" starts as False by default. The reasoning should explain the balance between the positive short-term and negative long-term factors leading to Medo.\n</think>\n\n{\n  \"raciocinio\": \"A notícia menciona que a meta fiscal de -0,25% do PIB é viável no curto prazo, o que poderia sugerir uma perspectiva positiva. No entanto, a menção às 'incertezas de médio e longo prazo devido aos desafios' indica cautela e preocupação com o futuro. A combinação de uma realidade atual aparentemente controlada com ameaças potenciais no futuro tende a gerar **Medo**, uma vez que o foco está nas dificuldades que ainda estão por vir e não totalmente resolvidas.\",\n  \"concordo\": false,\n  \"emocao\": \"Medo\"\n}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
          ]
        }
      ]
    }
  ]
}